import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.layers import Input
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import time  # To measure runtime

# Configure GPU memory growth (optional)
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)

# Paths and parameters
DATA_DIR = "Rice_Image_Dataset/Rice_Image_Dataset"  # Replace with your dataset path
IMG_SIZE = (64, 64)
BATCH_SIZE = 32
EPOCHS = 5

# Data preparation with ImageDataGenerator and dynamic splitting
datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,  # Normalize images
    validation_split=0.4  # Reserve 40% for validation and testing
)

# Training data (60%)
train_data = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Validation data (20%)
validation_data = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

# Test data (20% manually split from validation data)
test_data = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Function to plot runtime graph
def plot_runtime(epoch_times, model_name):
    plt.figure(figsize=(6, 4))
    plt.plot(range(1, len(epoch_times) + 1), epoch_times, marker='o', label='Time per Epoch')
    plt.axhline(y=np.mean(epoch_times), color='r', linestyle='--', label='Average Time')
    plt.xlabel('Epoch')
    plt.ylabel('Time (seconds)')
    plt.title(f'Runtime per Epoch ({model_name})')
    plt.legend()
    plt.show()

### CNN Model ###
def build_cnn(input_shape, num_classes):
    model = Sequential([
        Input(shape=input_shape),  # Use Input layer
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Train and evaluate CNN
def train_cnn():
    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)
    num_classes = len(train_data.class_indices)
    cnn_model = build_cnn(input_shape, num_classes)

    # Save flowchart using Graphviz
    plot_model(cnn_model, to_file="cnn_model_flowchart.png", show_shapes=True, show_layer_names=True)

    cnn_model.summary()

    # Track runtime per epoch
    cnn_epoch_times = []
    start_time = time.time()
    for epoch in range(EPOCHS):
        epoch_start = time.time()
        history = cnn_model.fit(train_data, validation_data=validation_data, epochs=1, verbose=1)
        epoch_end = time.time()
        cnn_epoch_times.append(epoch_end - epoch_start)
    end_time = time.time()

    # Save model
    cnn_model.save("cnn_rice_model.h5")

    # Evaluate and plot runtime
    test_loss, test_accuracy = cnn_model.evaluate(test_data)
    print(f"CNN Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
    plot_runtime(cnn_epoch_times, "CNN")
    print(f"CNN Total Runtime: {end_time - start_time:.2f} seconds")

    return cnn_model, history

### ANN Model ###
def build_ann(input_shape, num_classes):
    model = Sequential([
        Input(shape=input_shape),
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Train and evaluate ANN
def train_ann():
    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)
    num_classes = len(train_data.class_indices)
    ann_model = build_ann(input_shape, num_classes)

    # Save flowchart using Graphviz
    plot_model(ann_model, to_file="ann_model_flowchart.png", show_shapes=True, show_layer_names=True)

    ann_model.summary()

    # Track runtime per epoch
    ann_epoch_times = []
    start_time = time.time()
    for epoch in range(EPOCHS):
        epoch_start = time.time()
        history = ann_model.fit(train_data, validation_data=validation_data, epochs=1, verbose=1)
        epoch_end = time.time()
        ann_epoch_times.append(epoch_end - epoch_start)
    end_time = time.time()

    # Save model
    ann_model.save("ann_rice_model.h5")

    # Evaluate and plot runtime
    test_loss, test_accuracy = ann_model.evaluate(test_data)
    print(f"ANN Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")
    plot_runtime(ann_epoch_times, "ANN")
    print(f"ANN Total Runtime: {end_time - start_time:.2f} seconds")

    return ann_model, history


# Run training for both models
cnn_model, cnn_history = train_cnn()
ann_model, ann_history = train_ann()
